"2013-04-01","Programming","Languages","Ruby","How do you print leading zeros?",,"source"
"2013-5-30","Computer Architecture","Memory",,"What is data placement? What is optimal data placement?","data placement refers to where the data sits in memory with relation to the processor. The more often that data can effectively be placed in memory local to the processor that needs it, the more overall access time will benefit from the architecture.",
"2013-5-30","Computer Architecture","Memory",,"What is processor affinity?","It comes up in NUMA, where memory is associated with processors. The problem is when a thread is moved to another processor, without the memory moving with it. Processor affinity means that processors do not lose the local memory they're working with.",
"2013-5-30","Computer Architecture","Memory",,"What is UMA? What is NUMA?","UMA is uniform memory access. NUMA is non-uniform memory access. in UMA, all processors access memory via a shared bus. in NUMA, each processor has its own memory block it can access, and can access other processors' memory blocks via a bus.",
"2013-05-31","Data Science","Bayesian Intro",,"Why did bayesian statistics fall out of favor, replaced with frequentist?","Because people could use different priors and get totally different results","DS notes, page 33"
"2013-05-30","Data Science","Effect size, Meta-Analysis, and Heteroskedasticity",,"If a 95% confidence interval of the effect size includes 0.0, what does this tell us?","This tells us that the p-value is less than 0.05, and hence not statistically significant.","DS notes, page 30"
"2013-05-30","Data Science","Effect size, Meta-Analysis, and Heteroskedasticity",,"What are the ways of averaging the effects of different experiments across studies? what is this called?","This is Meta-Analysis. We give more weight to more precise studies using either simple method (weight is determined by sample size) or the inverse-variance (weight is determined by variance of study)","DS notes, page 31"
"2013-05-30","Data Science","Effect size, Meta-Analysis, and Heteroskedasticity",,"What is heteroskedasticity?","When members of a population have differing amounts of variance.","DS notes, page 31"
"2013-05-30","Data Science","Effect size, Meta-Analysis, and Heteroskedasticity",,"What is the effect size?","Also known as Standard Mean Difference. It is the (mean of experimental group) - (mean of control group) / standard deviation","DS notes, page 30"
"2013-05-29","Data Science","Eventual Consistency",,"What are the phases of two-phase commit","1.action leading to commit occurs 2. master prepares 3. slaves write to logs 4. slaves respond with 'ready' 5. master sends commit command","DS notes, page 23"
"2013-05-29","Data Science","Eventual Consistency",,"What are the three qualities databases can have?","Consistency, Availability, and Partitioning. Consistency means all nodes have the same data, availability means the system can be interacted with in the presence of failures, partitioning means that if two parts of a system can't take to each other, can they make progress on their own?","DS notes, page 23"
"2013-05-30","Data Science","Fraud and Benford's Law",,"What is benford's law? How can it be used to detect fraud?","Fraud is done when data is created with a logistic regression function. Benford's law states that in any sample of a population, the numbers associated with each sample will have a 30% chance of having a first digit of 1. It's been shown that numbers generated with logistic regression do not follow this law. Data must span many orders of magnitude","DS notes, page 31"
"2013-05-20","Data Science","MapReduce","Comparing MR and Dbs","What is one way that relational DBs are more scaleable than MR?","DS notes, page 22",
"2013-05-20","Data Science","MapReduce","Experimental Results: MR and DB","In what ways do DB's outperform MR? In what ways does MR outperform DBs?","DS notes, page 22/23",
"2013-05-20","Data Science","MapReduce","Matrix Implementation","What parallel architecture does MapReduce used? What is shared in it?","DS notes, page 19",
"2013-05-20","Data Science","MapReduce","Matrix Implementation","What are the phases in MapReduce, in general and in Hadoop?","DS notes, page 20",
"2013-06-13","Data Science","MapReduce","Matrix Implementation Overview ","How many times is each chunk replicated on a distributed file system?","DS notes, page 19",
"2013-05-20","Data Science","MapReduce","Matrix Multiply Table","Why do we emit an i,j from A for each one of the columns in B?","DS notes, page 19",
"2013-05-16","Data Science","MapReduce","MR Abstractions","In MapReduce, why must key-value pairs be relatively small?","The pairs must be small enough to fit on one machine",
"2013-05-16","Data Science","MapReduce","MR Abstractions","What is the MapReduce data model?","DS notes, page 16",
"2013-05-16","Data Science","MapReduce","MR Abstractions","What is the pseudocode representation of MapReduce?","DS notes, page 17",
"2013-05-16","Data Science","MapReduce","MR Pseudocode","What is the best way of improving MapReduce performance?","DS notes, page 17",
"2013-05-16","Data Science","MapReduce","MR Pseudocode","Where is the biggest bottleneck of MapReduce?","DS notes, page 17",
"2013-05-16","Data Science","MapReduce","MR Relational Join","Are kv pairs passed to different nodes based on their key during the shuffle phase?",,
"2013-05-16","Data Science","MapReduce","MR Relational Join","Why is the reduce task in a relational join a cartesian product?","DS notes, page 18","The Map phase produces key-value pairs that have a key that is being joined on, then distributes the tuples to the Reducers where each Reducer is given only tuples with the same key. Because each Reducer has a only tuples with the same key that we are joining on, a cartesian product will produce the correct answer for the join."
"2013-05-16","Data Science","MapReduce","MR Text Examples","What does a map function do with a document that is too large to handle?","DS notes, page 17",
"2013-05-16","Data Science","MapReduce","MR Text Examples","What function can stay constant while the other changes?","DS notes, page 17",
"2013-05-16","Data Science","MapReduce","MR Text Examples","What is an inverted index?","DS notes, page 17",
"2013-05-20","Data Science","MapReduce","Parallel Databases","What is a parallel query? How does it differ from a distributed query?","DS notes, page 21",
"2013-05-20","Data Science","MapReduce","Parallel Databases","How does Teradata implement their parallel query structure?","DS notes, page 21",
"2013-05-16","Data Science","MapReduce","Scalability","What is read trimming? How does it change processing time?","DS notes, page 14",
"2013-05-16","Data Science","MapReduce","Scalability","What is scaling up? What is scaling out?","DS notes, page 14",
"2013-05-16","Data Science","MapReduce","Scalability","What is the pattern that takes place when mapreduce is applied?","DS notes, page 15",
"2013-05-31","Data Science","Multiple Hypothesis Testing",,"How do you correct for multiple tests?","By using familywise error rate corrections. bonferroni finds alpha_c by dividing alpha (alpha is familywise error rate, I think it's related to p-value) by the number of hypotheses. Sidak correction asserts independence, and calls alpha equal to 1 - (1-alph_c)^k. then solve for alpha_c.","DS notes, page 32"
"2013-05-31","Data Science","Multiple Hypothesis Testing",,"What is the Benjamani-Hochberg Procedure?","1. compute the p-value of ech of m hypotheses, then order them in increasing order of p-value. compute for each: rank order of hypothesis / # of all hypotheses * alpha. reject all such that the p-value is not less than or equal to it.","DS notes, page 32"
"2013-05-31","Data Science","Multiple Hypothesis Testing",,"What is the false discovery rate?","essentially, it's precision with regards to correctly rejecting null hypotheses","DS notes, page 32"
"2013-05-31","Data Science","Multiple Hypothesis Testing",,"What is the problem with multiple hypothesis tests?","If you keep doing tests, eventually you'll have success.","DS notes, page 32"
"2013-05-28","Data Science","NoSQL Introduction",,"What is the motivation for NoSQL?","to have systems that scale to large amounts of servers","DS notes, page 23"
"2013-05-30","Data Science","Pig","Pig Evaluation","How does Pig apply relational algebra?","It looks at the group/foreach, etc commands, and finds where tasks could be better done in the map function","DS notes, page 30"
"2013-05-30","Data Science","Pig","Pig Functions","How does Pig's group by work?","It is simply a map reduce job; input is tuples, and each tuple is emited with the value you're asking for as the key, and the rest of the tuple as the value. these are then combined by key during reduce.","DS notes, page 28"
"2013-05-30","Data Science","Pig","Pig Intro","What is Pig? Is it a language?","No, it's a layer above MR that produces MR jobs.","DS notes, page 28"
"2013-05-30","Data Science","Pig","Pig Intro","What is the benefit of using Pig?","It is much faster to develop MR jobs, due to using relational algebra statements rather than writing mappers and reducers","DS notes page 28"
"2013-05-30","Data Science","Pig","Pig Join and Co-Group Join","How does cogroup work?","it's essentially a join, in that it grabs all records with matching keys and throws them into a bag. empty set given when there are no matches for one side.","DS notes, page 29"
"2013-05-30","Data Science","Pig","Pig Join and Co-Group Join","What are the three problems that occur in MR jobs? What algorithms are used to address these?","When one table is small, we can replicate this table across all other machines in memory, and hence perform the join ahead of time--Replication. When one reducer gets stuck with a bunch of mapped keys, we can then split up that reducer into more machines--Skew. When your dataset is already sorted, you can perform the join during the map phase--Merge","DS notes, page 29"
"2013-05-30","Data Science","Pig","Pig Join and Co-Group Join","What is the difference between cogroup and join?","join is two steps--create the groups, and then merge them into one tuple each. cogroup is just the first step.","DS notes, page 29"
"2013-05-16","Data Science","PA 2",,"How do you replicate matrix multiplication for sparse tables using sql?",,
"2013-05-16","Data Science","PA 2",,"What is one way of finding the list of documents most relevant to a search?",,
"2013-05-30","Data Science","Publication Bias",,"What explains the cause of the truth wearing off over multiple trials?","The fact that outstanding results are the ones that get published.",
"2013-05-30","Data Science","Publication Bias",,"What is publication bias?",,
"2013-05-31","Data Science","Recap & Big Data",,"What is the curse of big data?","correlations are bound to arise in large data sets","DS notes, page 33"
"2013-05-31","Data Science","Recap & Big Data",,"What happens as you increase N, the number of records?","Bias also tends to increase","DS notes, page 33"
"2013-05-12","Data Science","Relational Algebra","Project, Cross-Product, Equi-Join","Which is more efficient, set semantics or bag semantics?","Bag semantics, as leaving duplicates in place is more efficient; this is what bag does.","DS notes, page 9"
"2013-05-12","Data Science","Relational Algebra",,"What was the original database structure? What were the difficulties? What was its successor? What problems did its successor solve?","DS notes, page 6",
"2013-06-13","Data Science","Relational Algebra",,"What was the original database structure? What were the difficulties? What was its successor? What problems did its successor solve?","DS notes, page 6","source"
"2013-06-13","Data Science","Relational Algebra",,"What is the fundamental problem that relational databases solve?","DS notes, page 6 (briefly, the answer is physical data independence)","source"
"2013-05-16","Data Science","Relational Algebra",,"What are the three types of database functions? when are they used?","DS notes, page 11",
"2013-05-16","Data Science","Relational Algebra",,"What are two execution plans used by database optimizers? what determines what plan is used?","DS notes, page 11",
"2013-05-16","Data Science","Relational Algebra",,"What is logical data independence?","DS notes, page 13",
"2013-05-16","Data Science","Relational Algebra",,"What is physical data independence?","DS notes, page 13",
"2013-05-12","Data Science","Relational Algebra",,"What is the connection between mathematical algebra and relational algebra?","DS notes, page 7",
"2013-05-12","Data Science","Relational Algebra",,"What is the fundamental problem that relational databases solve?","DS notes, page 6 (briefly, the answer is physical data independence)",
"2013-05-12","Data Science","Relational Algebra",,"Which is more efficient, set semantics or bag semantics?","DS notes, page 9",
"2013-05-12","Data Science","Relational Algebra",,"How does the DB handle statements that are logically equivalent?","DS notes, page 9",
"2013-06-13","Data Science","Relational Algebra",,"What is the connection between mathematical algebra and relational algebra?","DS notes, page 7","source"
"2013-05-12","Data Science","Relational Algebra",,"How does the DB handle statements that are logically equivalent?","They are compiled into the same statement.","DS notes, page 9"
"2013-05-29","Data Science","Response to NoSQL Systems",,"How can you avoid using joins?","By nesting records underneath parent records; i.e. organizing them into one access path. This is how DBs were originally structured","DS notes, page 27"
"2013-05-29","Data Science","Response to NoSQL Systems",,"Why do enterprises avoid NoSQL?","DB's need to be correct for financial transactions. Also with 10k db's, there is a need for standardization--not usually doable in nosql systems","DS notes, page 27"
"2013-05-29","Data Science","Types of Distributed Systems","BigTable","Describe bigTable","It uses record-based transactions, joins are compatible with MR, there are integrity constraints. The data model is sparse, distributed, persistent multi-dimensional sorted map. Data is sorted by time.","DS notes, page 26"
"2013-05-29","Data Science","Types of Distributed Systems","BigTable","How are tablets used? How are they kept track of? How are they updated?","tablets hold data that is of similar timestamp(and maybe other qualities?). during a read operation, the sstables (tables on hard disk I guess?) are combined with memtable (memtable holds writes, I think), and when memtable gets too large, it either gets written to a new sstable, or all sstables are combined into one sstable","DS notes, page 26"
"2013-05-29","Data Science","Types of Distributed Systems","CouchDB","How are joins simulated?","Done using mapreduce. Beyond that I'm a little confused. In the example, he talks about emiting a different k-v pair in the map function for different types of data--i.e. a different key for posts and for comments.","DS notes, page 26"
"2013-05-29","Data Science","Types of Distributed Systems","CouchDB","What are the major qualities of couchDB?","The transactions are records-based (rather than granular k-v's, I think), it uses mapreduce for joins/analytics, and you can define views","DS notes, page 26"
"2013-05-29","Data Science","Types of Distributed Systems","CouchDB","What are the qualities of updates?","Full consistency within a document, lock-free concurrency (optimistic, which I don't know the meaning of), no multi-row transactions","DS notes, page 26"
"2013-05-29","Data Science","Types of Distributed Systems","Dynamo","What is configurable consistency?","I'm not 100% sure what it is, but it has to do with the R, W, and N factors. R is the # of nodes needed for successful read, W is same for write, and N is replication factor (not 100% sure but I think that's the number of nodes). If R+W > N, then you can claim consistency. If R + W < N, there is lower latency.","DS notes, page 25"
"2013-05-29","Data Science","Types of Distributed Systems","Dynamo","What is dynamo?","It is a key-value structure like memcache, and 99% of requests respond in 300ms","DS notes, page 25"
"2013-05-29","Data Science","Types of Distributed Systems","Dynamo","When do vector clocks conflict?","Vector clocks conflict when all values in one clock are not later than or equal to all values in the other clock.","DS notes, page 25"
"2013-05-29","Data Science","Types of Distributed Systems","Dynamo","When is reconciliation done?","At read time","DS notes, page 25"
"2013-05-29","Data Science","Types of Distributed Systems","Memcached","How does consistent hashing work?","each node knows the range that other servers deal with, and passes the key to them in log-n time","DS notes, page 24"
"2013-05-29","Data Science","Types of Distributed Systems","Memcached","What are the features of NoSQL?","check notes","DS notes, page 24"
"2013-05-29","Data Science","Types of Distributed Systems","Memcached","What are the major impact systems?","memcached (fast, scalable, no fault tolerance), dynamo (eventual consistency), bigtable (record storage scaled to 1000s of machines)","DS notes, page 24"
"2013-05-29","Data Science","Types of Distributed Systems","Memcached","What are the types of data organization in NoSQL systems?","document (nested values), extensible record (families of attributes have a schema, but new attributes may be added), key-value object (set of k-v's, no schema, no nesting)","DS notes, page 24"
"2013-05-29","Data Science","Types of Distributed Systems","Other Google Systems","What are the other google systems mentioned?","HBase, Megastore, Spanner, Tenzing","DS notes, page 27"
"2013-06-06","Data Science",,,"What are the two types of prediction?","Classification (categorical) and regression (learned attribute is numeric). Though I'm kinda confused by this because logistic regression is used for classification.",
"2013-06-08","Food","Coffee",,"How do you make French press coffee?","1. Boil 18 oz water. 2. Grind 2 tbsp per 6 oz. 3. Put grinds in press mug 4. Put water in 5. Stir 6. Put lid on, twist so as to block the opening. 7. Brew 5-10'mins. 8. Press down.","Talia"
"2013-06-05","Heroku","Troubleshooting",,"What do you do when you get a 500 error?","Make sure your database has been migrated with 'heroku run rake db:migrate', then restart the server. Be patient, it may take a while.",
"2013-05-03","Linux","Command Line",,"How do you find out what cron jobs are running?","ps -ef | grep bash","source"
"2013-05-03","Linux","Command Line",,"When you run ps, there are two process ids listed for each process. what is the difference between them?","the first is the process's pid. the second is that process's parent pid","source"
"2013-06-03","Linux","Command Line",,"How do you stop a cron job that is running?","Find out what the process id of the cron job is, and kill -9 on that process id.","source"
"2013-05-10","Linux","tar",,"How do you uncompress a tar.gz file?",,
"2013-05-10","Linux","tar",,"What is a tar.gz file?","an uncompressed archive",
"2013-04-09","Machine Learning","Cost Function",,"What is the cost function?","1/(2m) * sum(from i = 1 to m) of (h_sub_theta(x_i)) - y_i)^2.",
"2013-04-09","Machine Learning","Cost Function",,"What do we do with the cost function?","It is used in linear regression. we choose theta so as to minimize the cost function.",
"2013-06-06","Machine Learning","Decision Trees",,"How do we compute information gain?","It's entropy of all classifications (just the labels of our training set) minus the entropy of the attribute over the classifications it is associated with.","DS notes, page 38"
"2013-06-06","Machine Learning","Decision Trees",,"How do we define entropy?","We define it as the expected value of information. It is the sum over all events of the probability of each event times the information function of that event.","DS notes, page 37"
"2013-06-06","Machine Learning","Decision Trees",,"How do we define the information function for an event?","It is defined as the log(base 2) of the probability of an event.","DS notes, page 37"
"2013-06-06","Machine Learning","Decision Trees",,"How do we handle continuous attributes?","Group them together by information gain. One way to do this is to put them in order and create partitions that give the most information gain.","DS notes, page 38"
"2013-06-06","Machine Learning","Decision Trees",,"What are the problems with ID3 trees?","They are expensive to train, and they are prone to overfitting.","DS notes, page 38"
"2013-06-06","Machine Learning","Decision Trees",,"What is entropy?","It is a measure of unpredictability.","DS notes, page 37"
"2013-06-06","Machine Learning","Decision Trees",,"What is information gain?","It is the amount of information that knowing the value of an attribute gives us.","DS notes, page 38"
"2013-06-06","Machine Learning","Decision Trees",,"What is the ID3 algorithm?","It is an algorithm for creating a decision tree. First you choose the attribute with highest information gain, then create branches for each value of attribute. Examples are partitioned based on their attributes.","DS notes, page 38"
"2013-04-09","Machine Learning","Feature Scaling",,"What is one problem with gradient descent?","Features may not be on the same scale as each other. i.e. the size of a house is much larger than the number of bedrooms. if you look at the contours of the cost function, in these cases, the elipses will be extremely distorted. gradient descent will take many more steps to finish when this happens.",
"2013-04-09","Machine Learning","Feature Scaling",,"How do you fix the issue with features with unproportional scales?","by dividing each feature by a certain number--for example, divide each square footage number by the difference between the maximum and minimum of numbers in the set, and likewise with number of bedrooms. i.e. normalize them. you can also use x_1 - c_1 to make sure each feature has mean of 0.",
"2013-04-09","Machine Learning","Gradient Descent",,"What is the derivative of the cost function with respect to theta_j?","I'm not typing that, look it up",
"2013-04-09","Machine Learning","Gradient Descent",,"What does the cost function for linear regression always look like?","it always looks like a bow-shaped curve, with one global optima.",
"2013-04-09","Machine Learning","Gradient Descent",,"What is a different name for gradient descent, and why?","Batch gradient descent--'batch' because all examples are examined at the same time.",
"2013-04-09","Machine Learning","Gradient Descent",,"What is the m of the cost function?",,
"2013-04-11","Machine Learning","Gradient Descent",,"What are the advantages of gradient descent?","each iteration is cheap, O(n).",
"2013-04-09","Machine Learning","Gradient Descent",,"What is gradient descent?","It is the process by which we choose theta to minimize the cost function J(theta). You start with a vector of thetas, then keep changing theta so as to reduce J(theta) until we end up at a minimum.",
"2013-04-09","Machine Learning","Gradient Descent",,"What is one problem with gradient descent?","it is possible to fall into local optima rather than global optima",
"2013-04-09","Machine Learning","Gradient Descent",,"Give the formal definition of gradient descent","repeat until convergence: theta_j := theta_j - alpha * J_prime(theta). J_prime(theta) is the first derivative of J with respect to theta_j. update is carried out simultaneously for all thetas 0-n. i.e. compute right-hand side for all i, then update theta_i's",
"2013-04-09","Machine Learning","Gradient Descent",,"What is alpha in the gradient descent formula?","the learning rate",
"2013-04-09","Machine Learning","Gradient Descent",,"What does the learning rate control?","It controls the size of the step we take downward in each iteration",
"2013-04-09","Machine Learning","Gradient Descent",,"What happens as the local minimum is approached?","The steps taken by gradient descent will be smaller. So there is no need to decrease alpha over time.",
"2013-04-11","Machine Learning","Gradient Descent",,"What are the advantages of newton's method?","No parameter selection of alpha, needs fewer iterations.",
"2013-04-11","Machine Learning","Gradient Descent",,"What is the threshold when you should choose newton's method or gradient descent?","The threshold is related to the number of features. If n < 1000, use newton's method, as calculating the inverse of the Hessian matrix is straightforward. If n is around 50k, probably use gradient descent. if n is around 100k, definitely use gradient descent.",
"2013-04-09","Machine Learning","Learning Rate",,"How do you choose the ideal learning rate?","If you graph the minimized cost function against the number of iterations, it will be a gradually decreasing curve, as the cost function gets smaller with more iterations. try several rates on different orders of magnitude, I guess.",
"2013-04-09","Machine Learning","Learning Rate",,"What is a convergence test?","If your learning rate is too large, it may cause the iterations vs. cost function curve to diverge.",
"2013-04-11","Machine Learning","ML Naive Bayes","Generative learning algorithms","What is a discriminative algorithm?","algorithms like logistic regression, which aim to draw a line between two pre-defined sets of examples",
"2013-04-11","Machine Learning","ML Naive Bayes","Generative learning algorithms","What is a generative algorithm?","It is an algorithm that analyses two sets of examples and figures out what their relative probabilities of occurance and co-occurance are, and then draws from that example the probability of future examples belonging to those sets",
"2013-04-11","Machine Learning","ML Naive Bayes","Text Classification","How do we go about classifying an email as spam?","first create a vector that is based on a dictionary. the vector has binary values; 0 if the word does not exist in the email, 1 if it does. then populate vectors based on emails and the word occurences of words in the dictionary",
"2013-04-09","Machine Learning","ML Regression","Linear","How do you create polynomial regression?","by squaring/cubing/square-rooting the values of certain features and applying the same kind of theta coefficients.",
"2013-04-11","Machine Learning","ML Regression","Regularized Linear Regression","How does the update statement change for regularized linear regression?","For updating thetas of features 1 through j, subtract lambda/m * theta_j from the derivative of the cost function (see notes)",
"2013-04-11","Machine Learning","ML Regression","Regularized Linear Regression","note that (1 - alpha*lambda/m) - number < 1","Why?",
"2013-04-11","Machine Learning","ML Regression","Regularized Linear Regression","What is the normal equation adjusted for regularized linear regression?","theta = (X` * X + lambda * identity matrix with top left corner equal to 0)^-1 * X` * y",
"2013-04-11","Machine Learning","ML Regression","Regularized Linear Regression","What problem does the regularization of the normal equation solve?"," (X` * X + lambda * identity matrix with top left corner equal to 0) will now be invertible if there are more features than training examples (or other way around? I forget)",
"2013-04-11","Machine Learning","ML Regression","Regularized Logistic Regression","How do we change our logistic cost function to account for regularization?","add lambda/(2*m) * sum from 1 to n (theta_j^2) to it",
"2013-04-11","Machine Learning","ML Regression","Regularized Logistic Regression","How do we change our gradient descent update function to account for regularization?","for j > 0, subtract lambda/m * theta_j from it",
"2013-04-11","Machine Learning","ML Regression","Regularized Logistic Regression","How do we change the formula for newton's method?","theta_new = theta - Hessian_inverse * gradient vector remains the same. However the Hessian matrix gets lambda/m * identity matrix with top left corner set to zero added to it",
"2013-04-11","Machine Learning","ML Regression","Regularized Logistic Regression","How do we ensure that gradient descent is working?","make sure the cost function is decreasing over number of iterations",
"2013-04-10","Machine Learning","ML Regression",,"You could use linear regression and a threshold value to classify, but what is the problem with that?","If you have training examples that throw off the curve, the line that is drawn may not be accurate. See video 16 of 30 on openclassroom.",
"2013-04-10","Machine Learning","ML Regression",,"How do you create a probability function from the cost function?","use the sigmoid function. 1 / (1 + e ^z). plug your regression model into z. this gives a uniform mapping from 0 to 1.","http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning"
"2013-04-10","Machine Learning","ML Regression",,"What is the derivative of the logistic regression cost function with respect to theta_j?","same form as with linear regression: theta := theta - alpha * [1/m * sum from 1 to m of((hypothesis_fxn(x_i) - y_i)]",
"2013-04-10","Machine Learning","ML Regression",,"What is the general update function form?","theta := theta - alpha * cost function first derivative(theta)",
"2013-04-11","Machine Learning","Newton's method",,"What is the algorithm that Newton's method follows?","create a function f(theta) = derivative of cost function with respect to theta(theta). graph it with respect to theta. pick random theta. draw a tangent at this point, then find where that tangent is equal to zero. Find theta at that point. set theta to that value, repeat.",
"2013-04-11","Machine Learning","Newton's method",,"What is the formula for the assignment of the next theta?","theta_next = theta - cost function first derivative(theta) / cost function second derivative(theta)",
"2013-04-11","Machine Learning","Newton's method",,"How is the above derived?","theta_next = theta minus (theta - theta_next). theta - theta_next = f(theta) / f`(theta). plug in from there.",
"2013-04-11","Machine Learning","Newton's method",,"How is the vectorized version different?","The formula for updating is theta_next := theta - Hessian matrix inverse * first derivative of cost function with respect to all thetas (a vector where each element is a partial derivative to feature i). ",
"2013-04-11","Machine Learning","Newton's method",,"What is the formula for the derivative vector for the cost function?","1/m * sum from 1 to m of (hypothesis_fxn(x_i) - y_i) * x(i). ",
"2013-04-11","Machine Learning","Newton's method",,"What is the formula for the Hessian matrix?","H = 1/m * sum from 1 to m of hypothesis_fxn(x_i) * hypothesis_fxn(1-hypothesis_fxn(x_i)) * (x_i) * (x_i`)",
"2013-04-11","Machine Learning","Newton's method",,"What is the general form for vectorized newton's method?","check notes-- theta_next = theta - Hessian inverse times upside-down delta of cost function",
"2013-04-11","Machine Learning","Newton's method",,"How do you check that newton's method has converged?","By plotting J(theta) against # of iterations, and see if there is any more improvement left to gain",
"2013-04-10","Machine Learning","Normal Equation",,"What is the normal equation?","theta = inv(X * X`) * X` * y",
"2013-04-10","Machine Learning","Normal Equation",,"What is the normal equation used in place of?","Gradient descent, though there are still places where gradient descent is useful, as in logistic regresison",
"2013-04-10","Machine Learning","Optimization Objective",,"Why not choose the squared error as the cost function to use when training theta?","because many cost functions turn out to be non-convex, and finding global minimum is difficult",
"2013-04-10","Machine Learning","Optimization Objective",,"Why do we want to choose a cost function that penalizes answers so much?","In order to train theta to avoid these high values. remember that our hypothesis function is now the sigmoid function, which predicts values between 0 and 1. so it won't put out values of 0 or 1, so we never get to infinity or to 0. we just want to make sure the cost function makes sense--the further off it is, the higher the cost.",
"2013-04-10","Machine Learning","Optimization Objective",,"What function will we choose?","for y = 1, -log(h_theta(x)). for y = 0, -log(1 - h_theta(x))",
"2013-04-10","Machine Learning","Optimization Objective",,"Why don't we use the squared error?","Because it is of quadratic form, and will only give a cost of 1 at most--we want a higher penalty for being wrong.",
"2013-04-10","Machine Learning","Optimization Objective",,"What is the compact version of the cost function?","-y*log(h_theta(x)) - (1-y) * log(1 - h_theta(x))",
"2013-04-10","Machine Learning","Optimization Objective",,"Why is the above cost funciton formula equivalent to the discrete definition?",,
"2013-04-10","Machine Learning","Optimization Objective",,"Why did we choose the log function specifically for the cost function, whereas there are so many curves that go from 0 to infinity over [0,1]?","Because of maximum likelihood estimation. if it is applied to logistic regression model, we get the exact function we just came up with. Also, because the function is convex and has a global minimum.",
"2013-04-11","Machine Learning","Optimization Objective",,"How do we regularize?","By shrinking thetas uniformly.",
"2013-04-11","Machine Learning","Optimization Objective",,"What is the new cost functioN?","J(theta) = 1/(2m) * sum from 1 to m((hypothesis_fxn(x_i) - y_i)^2 + lambda * sum from 1 to n of theta_j^2). note we do not penalize theta_0",
"2013-04-11","Machine Learning","Optimization Objective",,"Why does shrinking thetas smoothen the curve?","?",
"2013-04-11","Machine Learning","Overfitting",,"What is overfitting?","When the hypothesis function is too sensitive, as it matches the training examples too well. i.e. it does not generalize well to new examples",
"2013-04-11","Machine Learning","Overfitting",,"What is it caused by?","too many features",
"2013-04-11","Machine Learning","Overfitting",,"What are the solutions?","throw out features (1) manually, or (2) with model selection algorithms. or, use regularization",
"2013-04-11","Machine Learning","Overfitting",,"When does regularization work well?","When there are many features and each contributes a little to predicting y.",
"2013-04-11","Machine Learning","Regularization","Common Variations","What happens if the training set is large?","We don't have to worry so much about regularization",
"2013-04-11","Machine Learning","Regularization","Common Variations","What is l_2-norm regularization?","lambda * sum(1 to n of theta_j^2) ~ theta` * theta ~ ||theta||_2 ^2",
"2013-04-11","Machine Learning","Regularization","Common Variations","What is l_1-norm regularization?","lambda * sum(1 to n of |theta_j|) ~ ||theta_0||_1",
"2013-04-11","Machine Learning","Regularization","Common Variations","What is the alternate version of the cost function?","instead of lambda/2*m, use lambda/2 against the sum of squared thetas. so that regularizaiton does not scale with m.",
"2013-06-04","Machine Learning","Regularization",,"How do we diagnose high bias vs. high variance?","If both the error of the training set and the error of the cross-validation set are high, then this is underfit, or high bias. If the error of the cross-validation is high, but the error of the trianing set is low, then this is overfit, or high variance.",
"2013-06-04","Machine Learning","Regularization",,"Why don't you use the test set data for cross-validation?","Because if you use the test set to choose the order of the model, you end up fitting the order of the model to the test set.",
"2013-06-04","Machine Learning","Regularization",,"How do you select your model during regression?","By using the cross validation set. Choose the order of the model which gives the lowest cost on the cross-validation set.",
"2013-06-04","Machine Learning","Regularization",,"How do you define the error function for logistic regression?","it is equal to 1 when the hypothesis outputs greater than 0.5 and the example is false, or when the hypothesis outputs less than 0.5 and the example is true.",
"2013-06-04","Machine Learning","Regularization",,"How do you visualize the effect that adding the regularization parameter has on the cost function?","imagine the cost function in 3-d, with theta_1 and theta_2 as the x-y axis, and the cost function as the z axis. What is the original cost function? What does it become when you add the regularization terms? ",
"2013-06-04","Machine Learning","Regularization",,"What are the terms for underfit and overfit?","high bias and high variance, respectively",
"2013-06-06","Machine Learning","Rules",,"What is sequential covering?","I don't really understand it. But it goes like this: for each class that we want to classify C, while our data set D is nonempty, construct a rule R that correctly classifies instances in D belonging to class C and does not incorrectly classify and non-C instances. Then add this rule to R, and remove from D all instances correctly classified by r. How do we construct rules? I think it's the next algorithm: while r incorrectly classifies some non-C instances of D, for each attribute-value pair in data item, get accuracy of r (already created rule) and a=v => C. Also, letting a*=v* be the a-v pair of maximum accuracy over D, update R by adding a*=v* to its antecedent. then you remove a* from A. This whole thing is General to Specific.","DS notes page 36"
"2013-06-06","Machine Learning","Rules",,"What is the rote classifier?","With each new data item, the classifier finds an already-classified specimen and assigns that specimen's classification to the new data item.","DS notes page 35"
"2013-04-11","Machine Learning","Support Vector Machines",,"What is a support vector?","training example (represented by a vector) that lies closest to the margin between classifications",
"2013-04-11","Machine Learning","Support Vector Machines",,"What does a support vector machine do?","It maximizes the margin around the hyperplane which separates classifications",
"2013-04-11","Machine Learning","Support Vector Machines",,"What is a hyperplane?","It is an n-dimensional plane that lines in n+1 dimensional space. for example a line on a 2-D graph, or a plane on a 3D graph.",
"2013-04-11","Machine Learning","Transfer Learning",,"What is lift?",,
"2013-04-11","Machine Learning","Transfer Learning",,"What is the difference between source task and target task?","source tasks are behavior from a large set of campaigns and user activity. target task is only specific to one campaign/client",
"2013-04-11","Machine Learning","Transfer Learning",,"What are the two stages of transfer learning?","the first is to generate learning based on a wide set of data, including data gathered from outside a campaign (before a campaign starts, there is no data to learn from it, so we have to use something). the second is to use the scores of several algorithms run in stage one, and combine those scores with information about the user, to generate scores for user",
"2013-04-11","Machine Learning","Transfer Learning",,"What is transfer learning?","learning that is done for a task that doesn't exactly match the target task, but is still useful in improving the learning of the target task",
"2013-04-11","Machine Learning","Transfer Learning",,,,
"2013-04-11","Machine Learning","Transfer Learning",,,,
"2013-04-11","Machine Learning","Transfer Learning",,,,
"2013-04-11","Machine Learning","Transfer Learning",,,,
"2013-04-09","Machine Learning","Vectorized Implementation",,"What is the prediction formula in vectorized form?","prediction = theta` * x (` means transpose)",
"2013-04-09","Machine Learning","Vectorized Implementation",,"What is the gradient descent equation in vectorized form?","theta = theta - alpha * delta. delta = 1/m * sum from i=1 to m of (h_theta(x_i) - y_i) * x_i",
"2013-06-06","Machine Learning",,,"What are the three components of learning, and what questions do they pose?","Representation (how do we define our classifier?), Evaluation (do we know whether the classifier is good or bad?), Optimization (how do we search among an infinite space of optimizations? Greedy search, gradient descent).","DS notes page 35"
"2013-06-06","Machine Learning",,,"What are the two types of machine learning?","Classification (categorical answers) and regression (numeric answers). Though I'm confused because logistic regression is used for classification.","DS notes, page 35"
"2013-06-06","Machine Learning",,,"What is the 1-Rule algorithm?","On the training set, look at one attribute of all data points and observe its value and classification. Count how often each classification appears. Then find the most frequent classification and make rule, if attribute = value, then class = c.","DS lecture, 03 Rules Part 1"
"2013-06-06","Machine Learning",,,"What's the difference between statistics and Machine Learning?","Statistics creates stochastic models that try to imitate real-world effects. Machine learning takes inputs and outputs and generates a system that makes the output match the inputs based on what it has learned.","DS notes, page 35"
"2013-05-04","Machine Learning",,,"What does the Receiver Operating Characteristic curve describe?","It illustrates the performance of a binary classifier system as its discrimination threshold is varied.","source"
"2013-04-08","Machine Learning",,,"How is the hypothesis function represented?","It is either a linear, quadratic, or other degree of polynomial function","source"
"2013-04-08","Machine Learning",,,"What are features of a classifier?","Characteristics of data points, as in cancer analysis, it may be age, size of tumor, clusters of tumors, etc.","source"
"2013-04-08","Machine Learning",,,"What are input variables?","Another word for features","source"
"2013-04-08","Machine Learning",,,"What are the hypothesis function coefficients represented by?","theta","source"
"2013-04-08","Machine Learning",,,"What is another expression for the hypothesis function?","h(x) = sum from i to n of (theta_i * x_i)","source"
"2013-04-08","Machine Learning",,,"What is the hypothesis function?","It is the function that maps input variables to output variables. It is used in linear regression","source"
"2013-04-08","Machine Learning",,,"What is the vector notation of the hypothesis function?","theta transposed * X","source"
"2013-04-10","Math","Linear Algebra",,"What is a non-invertible matrix, and how can it come about?","Also known as singular or degenerate, non-invertable matrixes have no inverse. Non-square matrices are usually non-invertible (but may have left- or right inverses). ",
"2013-04-11","Math","Probability","Bayesian Statistics","What is Bayes' rule?","p(x|y) = p(y|x) * p(x) / p(y)",
"2013-04-11","Math","Probability","Bayesian Statistics","Where does Bayes' rule come from?","p(x|y) = p(x & y) / p(y) and hence p(y|x) = p(x & y) / p(x)",
"2013-05-30","Math","Probability","Bayesian Statistics","What is a conjugate prior?","THe question is whether or not a conjugate prior exists for a liklihood function. (I don't fully understand how this is useful, but bear with me.) if the posterior distribution and the prior distribution are in the same family as the prior probability distribution, then the prior and posterior are conjugate distrubutions, and the prior is a conjugate prior for the liklihood.",
"2013-05-30","Math","Probability","Bayesian Statistics","What is the liklihood function?","It describes the liklihood that, given a set of observations, the parameters are biased in a certain way. I'm still not really sure what it's used for. It isn't the probability of a parameter, though.",
"2013-06-13","Math","Probability",,"What is Bayes' rule?","6/13","source"
"2013-04-29","PGM","Bayesian Networks",,"What is time invariance?","It means that it doesn't matter when the observations are made, the effects are the same. i.e. if X(t) = Y(t), then X(t + delta) = Y(T + delta)",
"2013-04-29","PGM","Bayesian Networks",,"How do deterministic functions affect independence in Bayesian networks?","if a node B is deterministic and influenced by A, then A's value determines what B is.",
"2013-04-29","PGM","Bayesian Networks",,"What does a double-circle in a network graph indicate?","That the independence of that node is conditional, I think",
"2013-04-24","PGM","Bayesian Networks",,"What are the two types of factor reduction?","When you reduce out a variable by choosing one value for it (marginalization?), and when you reduce out a variable by normalizing the remaining variables over all values of the variable you want to remove (renormalization?)",
"2013-04-24","PGM","Bayesian Networks",,"How do you draw a graph where two nodes are conditional upon each other?","I guess this just wouldn't be a bayesian network?",
"2013-04-22","PGM","Bayesian Networks",,"Given a bayesian network, what would the CPDs look like?","Each node of the graph has a CPD. The CPD is the distribution of probabilities for that node, across all the variables which influence that node.",
"2013-04-22","PGM","Bayesian Networks",,"What is the chain rule for Bayesian Networks?","It is a factor product. It is written as the product of each CPD. P(X_i,...,X_n) = Pi(P(X_i | Parents_G(X_i)). For example, P(A,B,C) = P(A|B,C)P(B|C)P(C)",
"2013-04-22","PGM","Bayesian Networks",,"Why is the Bayesian network a legal distribution?","Because P >= 0, and Sigma(P) = 1",
"2013-04-22","PGM","Bayesian Networks",,"What does well-defined mean?","It means the distribution sums to 1 over all examples",
"2013-04-22","PGM","Bayesian Networks",,"What is causal reasoning?","When you observe a cause, and see what that does to the probability of the effect.",
"2013-04-22","PGM","Bayesian Networks",,"What is evidential reasoning?","When you observe an effect, and see what that does to the probability of the cause.",
"2013-04-22","PGM","Bayesian Networks",,"What is intercausal reasoning?","When you observe one variable, and then observe another, and see what that second observation does to a given cause or affect.",
"2013-04-22","PGM","Bayesian Networks",,"What is explaining away?","It is when one cause is understood to be sufficient explanation for a certain phenomena--this changes the probability that it can be attributed to another phenomena, I thikn.",
"2013-04-22","PGM","Bayesian Networks",,"In what networks can X influence Y?","X -> Y, X <- Y, X -> W -> Y, X <- W <- Y",
"2013-04-22","PGM","Bayesian Networks",,"When can it not?","X -> W <- Y, also called a v-structure",
"2013-04-22","PGM","Bayesian Networks",,"When is a trail active?","When it has no v-structures",
"2013-04-22","PGM","Bayesian Networks",,"When can X influence Y given evidence about Z?","X->Y, X<-Y, X->W->Y (when W is not in Z, not when it is), X<-W<-Y (when W is not in Z, not when it is), X<-W->Y (when W is not in Z, not when it is), X->W<-Y (when W or one of it descendants IS in Z, not when it is not)",
"2013-04-22","PGM","Bayesian Networks",,"What is the definition of when a trail is active?","A trail X_1 - ... - X_n is active given Z if for any v-structure X_i-1 -> X_i <- X_i+1, we have that X_i or one of its descendants is in Z (is observed), and no other X_i is observed.",
"2013-04-22","PGM","Bayesian Networks",,"What is the definition of independence?","P satisfies A is independent from B if P(A,B) = P(A)P(B), P(A|B) = P(A), and P(B|A) = P(B). each of these is equivalent.",
"2013-04-22","PGM","Bayesian Networks",,"What is conditional independence?","When knowledge about some other variable C influences P(A|B)",
"2013-04-22","PGM","Bayesian Networks",,"How can variables lose their independence?","sometimes, gaining knowledge about other variables will cause variables to lose independence, as in v-structures.",
"2013-04-22","PGM","Bayesian Networks",,"Can variables be independent conditional on knowing one value of a variable, but lose its independence upon knowing another value of that variable?","pretty sure yes, but the arithmetic doesn't seem to check out.",
"2013-04-22","PGM","Bayesian Networks",,"What independence assumption does Naive Bayes make?","given the class variables, each observed variable is independent of the other observed variables",
"2013-04-22","PGM","Bayesian Networks",,"What is the odds ratio?","probability that the class is c1 given x_1,...,x_n divided by probability that the class is c_2 given x_1,...,x_n. not sure what this is useful for, though.",
"2013-04-22","PGM","Bayesian Networks",,"What is one reason Naive Bayes is so powerful?","Because we only have to think about pairwise interactions between the class variable and individual features",
"2013-04-22","PGM","Bayesian Networks",,"What is the independence assumption made in Naive Bayes?","Given a class, all features X_i and X_j are independent from each other",
"2013-04-22","PGM","Bayesian Networks",,"What is Bernoulli Naive Bayes?","When each feature takes a value of 0 or 1",
"2013-04-22","PGM","Bayesian Networks",,"What is multinomial Naive Bayes?","When each feature takes one of many values",
"2013-04-22","PGM","Bayesian Networks",,"When is Naive Bayes useful?","When there are many features and each one is weakly relevant",
"2013-04-22","PGM","Bayesian Networks",,"When is Naive Bayes not useful?","When the independence assumptions made are not correct; that is when features are actually strongly correlated",
"2013-04-22","PGM","Bayesian Networks",,"What does the independence assumption make possible?","The statement that P(C,X_1,...,X_n) = P(C) * product over all X's( P(X_i given C))",
"2013-04-22","PGM","Bayesian Networks",,"What was learned from the Pathfinder medical diagnosis?","Don't use zero probabilities--even if an event is rare, it is still possible, and zeros screw up predictions",
"2013-04-22","PGM","Bayesian Networks",,"What is an independent parameter?","In a CPD P(X|Y_1,...,Y_r), if each Y_i has k_i values, then we have a total of k_1*...*k_r*(m-1) independent parameters. I guess the parameters refers to the number of different values that can be entered as parameters to the equation that are independent from each other. it only applies to the graphical models of nodes that are conditional upon other nodes. if the node affects another node, then the affecting node is not affected by the affected node's paramters.",
"2013-04-22","PGM","Bayesian Networks",,"What is an I-map?","a map K is an independence map of G if every independence relationship in K is also in G",
"2013-04-22","PGM","Bayesian Networks",,"What are the rules you need to apply when finding conditional probabilities given some other conditional probabilities?","law of total probability, bayes' theorem, definition of conditional probability",
"2013-05-09","PGM","Bayesian Networks",,"How do you get the marginal factor from a group of factors, and with evidence?","Programming assignment 1",
"2013-05-09","PGM","Bayesian Networks",,"How can you vectorize your code? What functions can you use?","Programming assignment 1",
"2013-05-09","PGM","Bayesian Networks",,,,
"2013-05-09","PGM","Bayesian Networks",,,,
"2013-05-09","PGM","Bayesian Networks",,,,
"2013-05-09","PGM","Bayesian Networks",,,,
"2013-05-09","PGM","Bayesian Networks",,,,
"2013-06-06","PGM","Decision Theory","DT Maximum Expected Utility","Do action nodes have CPDs?","The actions themselves don't, but we create decision rules that do, in order to capture the randomness of information nodes. Still not sure what this CPD looks like.",
"2013-06-03","PGM","Decision Theory","DT Maximum Expected Utility","What is the value of delta^*_A?","1 if a is equal to the argmax of A for mu(A,z), 0 otherwise","PGM notes, page 46"
"2013-06-03","PGM","Decision Theory","DT Maximum Expected Utility","What do we use Z for?","Z is the parents of the action variables; the observations prior to A. This encapsulates information, I think. i.e. they are the information nodes","PGM notes, page 46"
"2013-06-03","PGM","Decision Theory","DT Maximum Expected Utility","Why is U only a function of the action and the state of the world?","Because that's how the utilty function is defined.","PGM notes, page 45"
"2013-06-03","PGM","Decision Theory","DT Maximum Expected Utility","How do we choose decision rules?","We find the decision rule which gives us the highest utility function value.","PGM notes, page 45"
"2013-06-03","PGM","Decision Theory","DT Maximum Expected Utility","What are information nodes?","They are nodes which influence action nodes","PGM notes, page 45"
"2013-06-03","PGM","Decision Theory","DT Maximum Expected Utility","Do action nodes have CPDs?","The actions themselves don't, but we create decision rules that do, in order to capture the randomness of information nodes","PGM notes, page 45"
"2013-06-03","PGM","Decision Theory","DT Maximum Expected Utility","What is the expected utility function?"," it is defined as EU[D[a]]=sum(over all states of the world) of P(state of world|action) * utility(state of world,action)","PGM notes, page 44"
"2013-06-03","PGM","Decision Theory","DT Maximum Expected Utility","What is a utility function?","it is a function U of states of the world (X) and possible actions (A).","PGM notes, page 44"
"2013-06-03","PGM","Decision Theory","DT Utility Functions","What is a micromort?","The value of a one in a million chance of death. $20 in 1980.",
"2013-06-03","PGM","Decision Theory","DT Utility Functions","What is the st petersburg paradox?","the game is this: flip a coin n times until it lands heads, and pay out 2^n. What should people pay to play? The payout value is potentially infinite, but most people will only pay $2","PGM notes, page 46"
"2013-06-03","PGM","Decision Theory","DT Utility Functions","If the variables T, K, D, L, and F are all binary valued variables, and the utility function is decomposed into U(T)+U(K)+U(D,L)+U(L,F), how many different utility values have to be elicited to characterize the utility function?","12",
"2013-06-03","PGM","Decision Theory","DT Value of Perfect Information","Consider the example of choosing between a job offered at two companies. Funding determines utility, state of the company determines funding, but we can't observe the state of the company directly. If we have a mole at one company, what determines how valuable that company is?","if there is a large difference in the chance of getting funding or not (based on the state of the company), then the value of information is higher. If the difference in expected utility between the two companies is high, the value of information is lower, as it only would change your mind about what company to choose in rare situations.","PGM notes, page 47"
"2013-06-03","PGM","Decision Theory","DT Value of Perfect Information","You just saw that the optimal decision only changes our mind if the second company is doing very well (s3). Recall that this only happens with prior probability 0.1. Do you think VPI will be high or low in this case?","The basic idea is that the gain in utility in this case has to be weighted by the probability of the state of the world that brings about that gain (i.e. the second company is doing very well). Because the probability of s3 is not very large we should not expect a very large gain in expected utility so the value of the information will likely be small.",
"2013-05-23","PGM","Belief Propagation","Clique Tree Algorithm","What is a clique tree?","It is an undirected tree. nodes are clusters, and edges between nodes are sepsets","PGM notes, page 37"
"2013-05-23","PGM","Belief Propagation","Clique Tree Algorithm","What is the correct expression for a given message from one cluster to another?","sum of all psi's over all variables not included in the next cluste, times the prior message","PGM notes, page 37"
"2013-05-23","PGM","Belief Propagation","Clique Tree Algorithm","When your factors are CPD's, how many cliques will they be assigned to?","only one","PGM notes, page 37"
"2013-05-23","PGM","Belief Propagation","Clique Tree Algorithm","How does the running intersection property change when you consider clique trees?","There is only one unique path from one node to the next. (Although I thought this was the case before.)","PGM notes, page 37"
"2013-05-23","PGM","Belief Propagation","Clique Tree Algorithm","Are the resulting beliefs from the clique tree algorithm correct?","yes","PGM notes, page 37"
"2013-05-23","PGM","Belief Propagation","Clique Tree Computation","Why does delta(B) never change?","Because the sum over A of psi1 is always the same","PGM notes, page 38/39"
"2013-05-23","PGM","Belief Propagation","Clique Tree Computation","What's the order in which messages are passed?","From leaf inward. for each node, no message is passed until all are received.","PGM notes, page 38/39"
"2013-05-23","PGM","Belief Propagation","Clique Tree Computation","How do we get the posterior distribution of variables appearing together in a clique?","By summing out irrelevant variables from any other clique containing the variables we want. If we get evidence Z=z, and if X appears in clique with Z, multiply that clique by indicator function, re-normalize","PGM notes, page 38/39"
"2013-05-23","PGM","Belief Propagation","Clique Tree Computation","How do we get the posterior distribution of variables that do not appear together in a clique?","Follow the same as for variables that do appear together, but apply this to all messages that affect the node we're interested in.","PGM notes, page 38/39"
"2013-05-23","PGM","Belief Propagation","Properties of BP","What does it mean to say that a cluster graph is calibrated?","If every pair of adjacent clusters Ci,Cj agree on their sepset Sij; sum of all beliefs are the same","PGM notes, page 36"
"2013-05-23","PGM","Belief Propagation","Properties of BP","What is a sepset?",,
"2013-05-23","PGM","Belief Propagation","Properties of BP","What happens at the convergence of belief propagation?","cluster graph beliefs are calibrated","PGM notes, page 37"
"2013-05-23","PGM","Belief Propagation","Properties of BP","What do we get as a result of cluster graph beliefs?","We get an alternative, calibrated parameterization of the unnormalized density (the unnormalized probability), because when we divide the cluster beliefs by the sepset beliefs, we get the product of all psi's, which is the unnormlaized measure","PGM notes, page 37"
"2013-05-21","PGM","Belief Propagation","Properties of Cluster Graphs","What is the Running Intersection Property?","For clusters that contain X, there's a path that contain X between those clusters. These paths must be unique--that is, paths can't form a loop.","PGM notes, page 35"
"2013-05-21","PGM","Belief Propagation","Properties of Cluster Graphs","What is the Family Preservation property?","It says that for every factor in the set of factors, there is a cluster such that the scope of that factor is equal to the cluster.","PGM notes, page 35"
"2013-05-21","PGM","Belief Propagation","Properties of Cluster Graphs","What is a Bethe cluster graph?","It is a graph that makes clusters out of all factors, and also adds singleton factors for each one","PGM notes, page 35"
"2013-05-21","PGM","Belief Propagation",,"What problem does belief propagation solve?","In markov graphs, we may have a group of factors that assign different values to random variables, and these values might not match between factors. belief propagation reconciles the factor differences.","PGM notes, page 33"
"2013-05-21","PGM","Belief Propagation",,"What is the belief propagation algorithm?","1. Assign each factor to a cluster. 2. Construct initial potentials. 3. Initialize all messages to 1. 4. Repeat: select edge and pass delta as defined in notes. 4. Compute beliefs using formula in notes--don't create feedback loops","PGM notes, page 34"
"2013-05-21","PGM","Belief Propagation",,"How useful is belief propagation?","It may not always converge, and the resulting beliefs are pseudo-marginals. But it's fast, I guess.","PGM notes, page 35"
"2013-05-24","PGM","Belief Propagation","BP in Practice","How do you construct a clique tree given a graph?",,
"2013-05-24","PGM","Belief Propagation","BP in Practice","What is the best type of BP?","Asynchronous with smoothing","PGM notes, page 41"
"2013-05-24","PGM","Belief Propagation","BP in Practice","What is informed message scheduling?","It uses tree reparameterization in order to calibrate messages.","PGM notes, page 41"
"2013-05-24","PGM","Belief Propagation","BP in Practice","What is message dampening?","using a different formula in computing messages; using weights to create new messages","PGM notes, page 41"
"2013-05-24","PGM","Belief Propagation","Clique Tree Independence","What is the theorem given in this section?","That a tree T satisfies the RIP if and only if all variables on ones side of the sepset are independent from all variables on the other side given the sepset variables.","PGM notes, page 39"
"2013-05-24","PGM","Belief Propagation","Clique Tree Independence","What is the minimal complexity incurred by any clique tree?","I guess it's the minimal amount of variables needed to create a sepset that makes two nodes independent","PGM notes, page 39"
"2013-05-24","PGM","Belief Propagation","Clique Trees and VE","When do we use Variable Elimination?","I think it's to create beliefs about factors. as we propagate through the tree and generate cliques, we build beliefs","PGM notes, page 40"
"2013-05-24","PGM","Belief Propagation","Clique Trees and VE","Why do we iterate over all variables in VE? What is left if we go through them all?","We're actually iterating over the variables to gain beliefs about them across all variables--I think variable elimination is necessary in order to gain fine-grained understanding of individual factors, over all other factors","PGM notes, page 40"
"2013-05-24","PGM","Belief Propagation","Clique Trees and VE","Why does VE induce a tree? Why does it satisfy family preservation and RIP?","it's a tree because each cluster has one parent; it's family preserving because each factor is used in some elimination step and therefor included in scope of associated psi; it obeys RIP because you know, because, it's a theorem.","PGM notes, page 40"
"2013-05-24","PGM","Belief Propagation","Clique Trees and VE","What is the cost of VE?","About the same as passing messages in one direction","PGM notes, page 40"
"2013-05-24","PGM","Belief Propagation","Loopy BP and Message Decoding","What coding theories use belief propagation?","Turbo codes, low-density parity checking codes","PGM notes, page 42"
"2013-05-24","PGM","Belief Propagation","Loopy BP and Message Decoding","What type of belief propagation is used in turbo codes?","Loopy","PGM notes, page 42"
"2013-05-24","PGM","Belief Propagation","Loopy BP and Message Decoding",,,
"2013-05-24","PGM","Belief Propagation","Loopy BP and Message Decoding",,,
"2013-05-28","PGM","MAP Estimation","Finding a MAP Assignment","What was she talking about in the video when she had passed the message to the middle factor, and recuded the table to two variables and took the values from them as maximums?",,
"2013-05-28","PGM","MAP Estimation","Max Sum Message Passing","How do we find the max args of a group of factors?","Use belief propagation. Use simple factor summation at each step of the message passing algorithm (I think), and take the combination of arguments that yeilds the largest value. The value of the factor will match over different parameters","PGM notes, page 43"
"2013-05-28","PGM","MAP Estimation","Max Sum Message Passing","What do you do when the maxes are not unique?","Either make arbitrary changes to inputs in order to get different values, or use traceback procedure that builds MAP assignment one variable at a time.","DS notes, page 23"
"2013-05-06","PGM","Knowledge Engineering",,"What are the three pairs of choices to make in constructing models?","PGM notes page 31",
"2013-05-06","PGM","Knowledge Engineering",,"In predicting the weather based only on the attire of individuals entering a building, would it make sense to construct a Naive Bayes model where the clothing of individuals is independent given the weather?",,
"2013-05-06","PGM","Knowledge Engineering",,"When would one use a linear gaussian? a conditional linear gaussian?","PGM notes page 32",
"2013-04-30","PGM","Markov Networks",,"What is the new unnormalized probability function under log-linear models?","PGM notes, page 28",
"2013-05-02","PGM","Markov Networks",,"What is I-equivalence?",,
"2013-05-02","PGM","Markov Networks",,"In an undirected graph, what is a clique?","search online",
"2013-05-02","PGM","Markov Networks",,"What is the relevance of cliques in constructing a probability distribution for an undirected graph?","search online",
"2013-05-02","PGM","Markov Networks",,"What is a polytree?","search online",
"2013-05-02","PGM","Markov Networks",,"What is a directed tree?","search online",
"2013-04-30","PGM","Markov Networks",,"What does degenerative mean?",,
"2013-04-30","PGM","Markov Networks",,"What does it mean to capture independencies in P?","PGM notes, page 26",
"2013-04-30","PGM","Markov Networks",,"Why are sparse graphs desirable?","PGM notes, page 26",
"2013-04-30","PGM","Markov Networks",,"What is a minimal I-map? Will it capture I(P)?","PGm notes, page 26",
"2013-04-30","PGM","Markov Networks",,"What is a perfect map?","PGM notes, page 26",
"2013-04-30","PGM","Markov Networks",,"Is the diamond Markov map for A, B, C, D where P satisfies A indep from C given B, D and B indep from D given A, C a perfect map?","PGM notes, page 26",
"2013-04-30","PGM","Markov Networks",,"Are perfect maps unique?","PGM notes, page 27",
"2013-04-30","PGM","Markov Networks",,"What happens when we define w = -log(a)?","PGM notes, page 28",
"2013-04-30","PGM","Markov Networks",,"What is w in log-linear models? How are they developed?","PGM notes, page 28",
"2013-04-30","PGM","Markov Networks",,"What is mu used to define? What are some examples of different mu functions?","PGM notes, page 29",
"2013-04-30","PGM","Markov Networks",,"What is an MRF?","PGM notes, page 29",
"2013-04-30","PGM","Markov Networks",,"In shared features, what is the energy function applied to?","PGM notes, page 30",
"2013-04-30","PGM","Markov Networks",,"How do we define repeated features?","PGM notes, page 30",
"2013-04-30","PGM","Markov Networks",,"What are the benefits of using shared features in log-linear models?","PGM notes, page 30",
"2013-04-29","PGM","Markov Networks",,"What is a pairwise Markov network?","A pairwise Markov network is an undirected graph whose nodes at X1,...,Xn and each edge Xi-Xj is associated with a factor Psi(Xi, Xj)",
"2013-04-29","PGM","Markov Networks",,"How do we get the probability distribution of a pairwise Markov network?","multiply all factors in the network by each other and divide by the partition function, i.e. the normalizing constant, i.e. the sum of all factors",
"2013-04-29","PGM","Markov Networks",,"From a probability distribution of a Markov network, how do we get the probability distribution of a single pair?","reduce out the other factors",
"2013-04-29","PGM","Markov Networks",,"Consider a fully connected pairwise network over X1,...,Xn where each Xi has d values. How many parameters does this network have?","O(n^2 * d^2)",
"2013-04-29","PGM","Markov Networks",,"Why must we move away from the probability distribution construction introduced before in pairwise Markov networks?","Because there will be O(d^n) free parameters for a full probability distribution",
"2013-04-29","PGM","Markov Networks",,"What is a Gibbs distribution?","it is defined by general factors Phi_i(Di) where each D has a scope of more than 2 variables. big_phi = {phi_i(D1),...,phi_k(Dk)}. unnormalized measure of (X1,...,Xn) = product of all phi_i's of (Di). Partition function Z_phi = sum of all unnormalized measures over all X's. final Gibbs probability distribution is the partition function multiplied by the unnormalized measure.",
"2013-04-29","PGM","Markov Networks",,"What is an induced markov network of a Gibbs distribution?","It is the graph implied by the distribution functions.",
"2013-04-29","PGM","Markov Networks",,"When does P factorize over H?","PGM notes page 22",
"2013-04-29","PGM","Markov Networks",,"When is a trail in a markov network active?",,
"2013-04-29","PGM","Markov Networks",,"Why is it impractical to apply naive Bayes to problems in which lots of features are correlated?",,
"2013-04-29","PGM","Markov Networks",,"What is the definition of conditional random field, and how does it differ from Gibbs?",,
"2013-04-29","PGM","Markov Networks",,"What happens if you introduce a new factor phi(D), where D is in X?","PGM notes, page 24",
"2013-04-29","PGM","Markov Networks",,"What function do we use to represent our phi(D)'s?","PGM notes, page 24",
"2013-04-29","PGM","Markov Networks",,"What does it mean to say that two nodes X and Y are separated in H given Z?","PGM notes page 25",
"2013-04-29","PGM","Markov Networks",,"What is the relationship between independence and factorization in Markov networks?","PGM notes, page 25",
"2013-04-30","PGM","Markov Networks",,"What are features in log-linear models?","PGM notes, page 28",
"2013-05-15","PGM","PA2",,"How do you compute the number of parameters in a CPD?","m outcomes * n evidence states is the # of entries in the CPD; m-1 outcomes * n evidence states is the # of parameters",
"2013-05-15","PGM","PA2",,"What is a decoupled network?",,
"2013-05-15","PGM","PA2",,"How do you find the total number of independent paramters in a coupled network?","https://class.coursera.org/pgm-003/forum/thread?thread_id=255 krassimir's answer is right, just don't multiply by the number of different types of nodes",
"2013-05-14","PGM","PA2",,"How do I vectorize this shit?",,
"2013-05-14","PGM","PA2",,"In problem 5 (in assignment 2), how do you index genotype variables?","they are actually the variables of each individual",
"2013-05-13","PGM","PA2",,"In what order do variable assignments change in the assignment table?","first variable iterates through its values while holding the second constant, and so on for the third",
"2013-05-13","PGM","PA2",,"What is a gene copy?",,
"2013-05-16","PGM","PA3",,"Why are they called singleton factors?","because they operate on single characters--which are the 16x8 matrices",
"2013-04-29","PGM","Structured CPDs",,"What is the graphical model of a continuous variable?","Similar to other models--a handful of variables affect the observation variable",
"2013-04-29","PGM","Structured CPDs",,"What function represents this kind of model?","a linear Gaussian. For Y determined by X1,...,Xk, Y ~ N(w0 + sum(wi * Xi) ; stddev^2). variance does not depend on parents.",
"2013-04-29","PGM","Structured CPDs",,"What is a conditional linear gaussian?","Same as above, except Y is also affected by A. In this case, variance can depend on A. ",
"2013-04-29","PGM","Structured CPDs",,"What is the shape of the robot motion model?",,
"2013-04-25","PGM","Structured CPDs",,"What's the difficulty in using tabular representations of CPDs for all CPDs?","There are 2^number of parents of possibilities for a given node, leaving to huge CPD tables",
"2013-04-25","PGM","Structured CPDs",,"What is context-specific independence?","it's when P satisfies (X independent of Y given certain assignment(s) c GIVEN Z, assignment(s) c)",
"2013-04-25","PGM","Structured CPDs",,"What is a multiplexer CPD?","It is a tree structure where the main node has multiple dependencies, plus a dependency A which tells the main node which one of the other dependencies the main node is to take the value of. the main node depends on one of the values in some contexts, determined by the other dependency, and not in others.",
"2013-04-25","PGM","Structured CPDs",,"What is a noisy CPD?","It is a tree that separates the variables being activated or not from their probabilities in inducing the target variable to be true. there is also a leak probability, which is the probability of the target variable being activated on its own.",
"2013-04-25","PGM","Structured CPDs",,"What context-specific independencies are induced by a noisy OR CPD?","X1 is conditionally indpendent from X2 when we observe Y = 0, as Y = 0 blocks the trail of influence from Y to X.",
"2013-04-25","PGM","Structured CPDs",,"What is meant by there being no interaction between causes?","dunno, they can influence one another.",
"2013-04-25","PGM","Structured CPDs",,"In the sigmoid CPD, what happens when one Xi goes from 0 to 1?","the probability increases by a factor of e^wi.",
"2013-04-25","PGM","Structured CPDs",,"In the sigmoid CPD, what happens as the parents Xi are turned on, and the larger wi's are?","the more likely Y is true.",
"2013-04-29","PGM","Template Models",,"What is the markov assumption?","a stochastic process has the Markov property if the CPD of future states depends only on the present state.",
"2013-04-25","PGM","Template Models",,"What is a HMM?","It is a structured transition model which describes the CPD of each state of moving into each of the other states on the next temporal step",
"2013-04-25","PGM","Template Models",,"What is HMM a subset of?","It is a subclass of Dynamic Bayesian Networks.",
"2013-04-25","PGM","Template Models",,"What does it mean that HMMs seem unstructured at the level of R.V.'s?",,
"2013-04-25","PGM","Template Models",,"What is a plate model?","It is a graphical representation of objects of the same type and same probabilistic model.",
"2013-04-25","PGM","Template Models",,"What is the difference between nested and overlapping plates?","In nested plates, all models nested in another plate are explicitly affected by that plate's model. overlapping plates are for models that are not influenced by other models.",
"2013-04-25","PGM","Template Models",,"What are the input parameters?","They are parameters for each model that affect that model, independent (?) of the affects of other models",
"2013-04-25","PGM","Template Models",,"What is collective inference?","It is looking at a number of instantiations of these plates and observing behavior on an aggregate level--this gives us more power than just seeing how posterior probabilities are affected by changing our inputs (I think)",
"2013-04-25","PGM","Template Models",,"What is the plate dependency model?","For a template variable A(U1,...,Uk) where Ui are the object types, the variable has parents B1(U1),...,Bm(Um). Each U1 is a subset of the set {U1,...,Uk}. This is to say that you can't have indexes in parents that are not in the children.",
"2013-04-24","PGM","Template Models",,"What benefits do template models provide over normal bayesian networks?","None except that it's easier to construct large networks using the same CPDs",
"2013-04-24","PGM","Template Models",,"What assumptions do we make in temporal models?","markov assumption, time invariance",
"2013-04-24","PGM","Template Models",,"How do we factor the CPD of a transition model?","We're finding P(W`,V`,L`,F`,O`|WVLF). Use the chain rule. see notes.",
"2013-04-24","PGM","Template Models",,"What is a 2TBN?","It is a two-time-slice bayesian network. it is a model over X1, ..., Xn specified as a BN fragment such that (1) the nodes include X`1, X`n and a subset of X1,...,Xn, (2) only the nodes X`1 have parents and a CPD, (3) the 2TBN defines a conditional distribution P(X`|X) = Pi from 1 to n of P(X`i|Parent)",
"2013-04-24","PGM","Template Models",,"What is a DBN?","It is a Dynamic Bayesian Network over X1,...Xn defined by a 2TBN BN-> over X1,...,Xn, and a Bayesian network BN(0) over X(0)1,...,X(0)n",
"2013-04-24","PGM","Template Models",,"What is a Ground Network?","Also called an unrolled network. For a trajectory over 0,...,T we defined a ground network such that (1) the dependency model for X(0)1,...,X(0)n is copied from BN(0), and the dependency model for X(t)1,...X(t)n for all t > 0 is copied from BN->",
"2013-04-25","PGM","Template Models",,"With a set of nested/overlapping plates, each variable is defined by their object types. What would a given instance of an variable that is within three nested/overlapping plates represent? Would it represent instances of the object types (the Uis mentioned above), or instances of the variables themselves (the A's mentioned above)","It would represent instances of the variables, not instances of the object types. It's the difference between grouping things by what they are, rather than by their characteristics. In the quiz example, teachers and courses overlap and are nested within schools. at the deepest nested level, we're looking at teachers from a given school teaching a certain class, rather than teachers of expertise E teaching a class of difficulty D at a school at location L. E,D,L are parameters, not the things we are observing.",
"2013-04-25","PGM","Template Models",,"Let A and B be random variables inside a common plate indexed by i. Is there an instance of A and an instance of B for every i?","Yes.",
"2013-04-24","PGM","Template Models",,"What is a template variable?","It is a model that is repeated throughout a model--there is sharing between and within these models",
"2013-04-24","PGM","Template Models",,"What is a template model?","template models are languages that specify how ground variables inherit dependency model from template",
"2013-04-22","PGM",,,"What do each Probabilistic, Graphical, and Models mean?","Probabilistic: brings a declarative representation with clear semantics, powerful reasoning patterns, and established learning methods. Graphical: lots of variables captured in random variables. Models: Declarative representation of our view of the world.",
"2013-04-22","PGM",,,"What is a Bayesian network?","it is a directed graph where the nodes are random variables",
"2013-04-22","PGM",,,"What is one problem with pure machine learning?","It isn't as specific as PGM are; remember the image segmentation of the cow and the car.",
"2013-04-22","PGM",,,"What is renormalization?","it is setting one variable to a constant value and finding the probability distribution of the remaining variables by dividing each of those variables' probabilities by the sum of all probabilities.",
"2013-04-22","PGM",,,"What is marginalization?","It is removing one variable from the distribution entirely",
"2013-04-22","PGM",,,"What is a factor?","It is a function or a table of values. It is defined as Phi(X_1, ... , X_n) => real-numbered value. Its scope is all the random variables which comprise it.",
"2013-04-22","PGM",,,"What is an unnormalized measure?","It is when you hold one variable constant to one value across all other values of other variables, without normalizing those values. It is a factor.",
"2013-04-22","PGM",,,"What is factor marginalization?","It is reducing out variables of a factor by adding up all values of other variables across all values of the variable you are removing",
"2013-04-22","PGM",,,"What is factor reduction?","removing one variable using factor marginalization, i think",
"2013-04-22","PGM",,,"What is a markov network?","It is an undirected graph",
"2013-06-06","Programming","Javascript",,"How do you override the action of a submit button?","Write a function that grabs the form when submit is clicked and manually passes the parameters. Be careful to use a post request, and when you do, remember that post doesn't pass data in the same way as get.",
"2013-04-02","Programming","Javascript",,"What does having a Javascript runtime even mean? is it like the JVM?",,"source"
"2013-03-04","Programming","Javascript",,"How do you parse xml?","call $parseXML on the xml, and then call $(data).find('<tag here>').each for each tag you want to get","source"
"2013-03-04","Programming","Javascript",,"What is a closure?","it is a funciton that contains both the function and the environment in which the function was created; hence, you can have variables that were passed into that function as parameters when that function was defined.","source"
"2013-04-04","Programming","Javascript",,"What happens when you surround a variable with $() in javascript?","$ is shorthand for the library used, such as $ is short for jQuery. jQuery() is a function that returns an element given an identifier. hence. $() returns an identifier.","source"
"2013-04-04","Programming","Javascript",,"what's the difference between $.get and $.ajax?","$.ajax is a pure http request that accepts configurations. $.get is $.ajax with some of those configurations already set.","source"
"2013-05-03","Programming","PHP",,"What do you use to encode urls?","urlencode(), duh","source"
"2013-04-03","Programming","Python",,"Are case statements supported?","No. if-else instead.","source"
"2013-04-03","Programming","Python",,"Are hashes and objects the same thing?","err... no.","source"
"2013-04-03","Programming","Python",,"Are there blocks in python?","no","source"
"2013-04-03","Programming","Python",,"Are there default return values in Python?","no","source"
"2013-04-03","Programming","Python",,"Are there module mixins, as in Ruby?","no","source"
"2013-04-03","Programming","Python",,"How can you emulate first-class functions in Ruby?","using procs","source"
"2013-04-03","Programming","Python",,"How do you determine your system's processor type?","cat /proc/cpuinfo for procesor info, uname -a for operating system type","source"
"2013-04-03","Programming","Python",,"How is Python's importing more fine-grained?","You don't import huge libraries, you import the pieces you need. You say 'from xyzlib import somemethod'. you can also import any number of methods from a module","source"
"2013-04-03","Programming","Python",,"How is Python's map function superior to Ruby's?","It forces the coder to factor things out into granular methods. much easier to read and fix, more maintainable","source"
"2013-04-03","Programming","Python",,"Name three things that take time in programming. (sorry, I'm still learning how to write questions.)","hash table lookups, allocations, copying","source"
"2013-04-03","Programming","Python",,"What is a filter?","similar to a map, it takes two arguments, a method name, and a list. the method is a boolean method, and the filter returns all members of the list that return true when passed to the method.","source"
"2013-04-03","Programming","Python",,"What is a map?","it takes two arguments, first is a method name, second is a list. it applies the method to each member of the list.","source"
"2013-04-03","Programming","Python",,"What is a proc?","it is an object that calls a function with fixed arguments. see the proc description page","source"
"2013-04-03","Programming","Python",,"What is a tuple?","it is a list that can't change","source"
"2013-04-03","Programming","Python",,"What is an anonymous function?","used in maps and filters, they are defined inline with the map/filter arguments","source"
"2013-04-03","Programming","Python",,"What is faster, reading a field from a struct in C, or reading an attribute in Python?","apparently, they are both the same speed","source"
"2013-04-03","Programming","Python",,"What is Python's version of a hash?","a list","source"
"2013-04-03","Programming","Python",,"What is Python's version of an array?","a list","source"
"2013-04-03","Programming","Python",,"What is the Enumerable map method?","it is a block method, and it returns an Enumerable with each member of the original Enumerable applied to the code specified in the block","source"
"2013-04-03","Programming","Python",,"What is the problem with dynamic typing?","No problem. optimization is done with tracing JIT's, method JITs, and predictive type inferencers","source"
"2013-04-03","Programming","Python",,"What takes the place of Rubys Enumerable functionality?","built in functions like map, reduce, filter","source"
"2013-04-03","Programming","Python",,"What values evaluate to false?","0,{},None,(nil),[],(),''","source"
"2013-04-03","Programming","Python",,"Why is python slower than c in a function that returns an array of squares?","because on each pass of the loop, python reallocates the side of the array, whereas this is done beforehand in C","source"
"2013-04-03","Programming","Python",,"Why might Python be superior?","1. bigger community 2. more consistent syntax 3. the source of imported functionality is obvious 4. explicit class & method structure makes code easier to follow","source"
"2013-04-03","Programming","Python",,"Does Python support inner methods?","yes","source"
"2013-04-04","Programming","Rails",,"How do you get a controller to respond with xml based on a view?","in the controller, put: response.headers['Content-type'] = 'text/xml; charset=utf-8'
                render :layout => false. also, create a view with .xml.erb extension, with whatever <%= %> tags that make sense to fill it out.","source"
"2013-04-04","Programming","Rails",,"How do you get a controller to respond with xml?","in the controller, use render(object_to_convert_to_xml.to_xml)","source"
"2013-04-03","Programming","Regular Expressions",,"What does [/w+-d+/] mean?","arbitrary number of letters, then a hyphen, then an arbitrary number of integers","source"
"2013-04-01","Programming","Ruby",,"What does each part of < '%03d' % 5 > mean?","Left side is a printf format string, right side is the value to put into those spaces. 03 means pad the number to 3 spaces","source"
"2013-04-01","Programming","Ruby",,"What does the * in [*1..30] do?",,"source"
"2013-04-01","Programming","Ruby",,"What's the difference between a do block and a {||} block?","do-end seems to be used when you don't want to do anything with the return value of the block, braces are used when you do want to do something with it","source"
"2013-04-01","Programming","Ruby",,"When you call a method inside a method such as self.method, and this is done within a self.method, which method is getting called, an object method, or a class method?",,"source"
"2013-04-02","Programming","Ruby",,"How do you sent HTTPS post requests with ruby?","require both 'uri' and 'net/https'. create http objects like normal, but set http.use_ssl to true.","source"
"2013-04-02","Programming","Ruby",,"What does extract_options! do?","it takes a list of args, and puts them into an arguments array and an options hash, respectively","source"
"2013-05-04","Programming","Ruby",,"How do you iterate through each line of a file?","first open a file for reading, then call file.each_line do |line| on it.","source"
"2013-04-26","Programming","Ruby",,"what's wrong with this: strings.each {|s| s = s + 'banana'}","the members of strings won't get updated, they're just copies I guess.",
"2013-04-16","Programming","Ruby",,"Are collections passed by reference or by value to arguments?","by reference",
"2013-04-16","Programming","Ruby",,"How do you sort a hash by value?","Hash[hash.sort_by {|key, value| value}]",
"2013-04-03","Programming",,,"What does first class function mean?","this means that functions are treated as first-class citizens. that is, they can be passed as arguments, they can be returned from other functions, just like objects and other data structures are.","source"
"2013-04-03","Programming",,,"What is a JIT?","stands for Just In Time.","source"
"2013-04-03","Programming",,,"What two things, broadly, cause slowness?","data structures and algorithms","source"
"2013-06-03","Programming",,,"What is a cache?","Two main types--memory cache and disk cache. memory cache is held in SRAM, as opposed to DRAM. SRAM is faster. Current computers use L2 or L3 cache. When accesses are made from disk, the most recent contents are kept in memory.","source"
"2013-06-04","Statistics","Line smoothing",,"What is double exponential smoothing?","similar to exponential smoothing, except each next statistic is also affected by a term b, which is determined by previous statistics and a smoothing factor B.",
"2013-06-04","Statistics","Line smoothing",,"What is exponential smoothing?","given discrete data points {x_1,...,x_n}, we form a new curve of points {s_1,...,s_n} which are defined as s_1 = x_0, and s_t is s_t-1 + alpha(x_t-1 - s_t-1). basically we compute each next s_t by modifying the previous s_t-1 by whatever alpha we choose.",
"2013-05-30","Statistics",,,"What is a test statistic?","it is a function of the sample; it is a numerical summary of the data set.","http://en.wikipedia.org/wiki/Test_statistic"
"2013-06-06","Talia","Birthday",,"When is talias birthday?","June 6",
"2013-04-09","Work","Akamai",,"How is the akid determined if not by a cookie?","It seems it actually is determined by a cookie.",
"2013-05-04","Work","User Modeling",,"what is one weakness of demographic/behavioral targeting?","the segments of users are not created using any feedback from individual advertisers, and usually represent large interest groupos. also, the targeting methods are based on clicks rather than on actual purchases","source"
"2013-05-04","Work","User Modeling",,"What is the difficulty of using advertiser data in addition to demographic/behavioral targeting?","now the platform has to find a different segment for each advertiser, and thus solve orders of magnitude more optimization problems","source"
"2013-05-04","Work","User Modeling",,"What is the frequency of an event?","number of days in which use has performed the event; recall the types of events above","source"
